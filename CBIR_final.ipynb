{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eD7p0gL4xQPn"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install required Dependencies"
      ],
      "metadata": {
        "id": "2obuJkPEX3tW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "jejmZSsrvSGe"
      },
      "outputs": [],
      "source": [
        "!pip install tenseal cryptography numpy pillow torchvision pycryptodome"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lntjw3WVCmLb"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making Directories to store different data\n",
        "\n",
        "*   encrypted_images: To store encrypted images\n",
        "*   encrypted_features: To store encrypted feature vectors of images\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fgPbrVoSBP9f"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hU_Tl6rWCujp"
      },
      "outputs": [],
      "source": [
        "os.makedirs(\"/content/drive/MyDrive/CBIR_AES_FHE/data\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/CBIR_AES_FHE/data/encrypted_images\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/CBIR_AES_FHE/data/encrypted_features\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCxaWrwSY_n5"
      },
      "source": [
        "Creating JSON File for mapping:\n",
        "\n",
        "*   encrypted_images -> encrypted_features\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBYUhVXQ3Qof"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "# File path for the JSON file (make sure to include the file name)\n",
        "json_file_path = \"/content/drive/MyDrive/CBIR_AES_FHE/data/mapping.json\"\n",
        "\n",
        "# New data to append\n",
        "new_mapping = {\n",
        "    \"encrypted_feature_vector_3\": \"encrypted_image_3.aes\",\n",
        "    \"encrypted_feature_vector_4\": \"encrypted_image_4.aes\"\n",
        "}\n",
        "\n",
        "# Check if the JSON file already exists\n",
        "if os.path.exists(json_file_path):\n",
        "    # Load existing data\n",
        "    with open(json_file_path, \"r\") as json_file:\n",
        "        mapping_data = json.load(json_file)\n",
        "else:\n",
        "    # Create an empty dictionary if file does not exist\n",
        "    mapping_data = {}\n",
        "\n",
        "# Update the mapping with new data\n",
        "mapping_data.update(new_mapping)\n",
        "\n",
        "# Save the updated data back to the JSON file\n",
        "os.makedirs(os.path.dirname(json_file_path), exist_ok=True)\n",
        "\n",
        "with open(json_file_path, \"w\") as json_file:\n",
        "    json.dump(mapping_data, json_file, indent=4)\n",
        "    print(f\"Updated JSON mapping file saved at: {json_file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uVhuMFr4-Z2"
      },
      "source": [
        "This is the **Context Genaration function**.\n",
        "\n",
        "*   Creates private and public context files.\n",
        "*   Every image is encrypted by the public context and decrypted by the private context.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbXwI1Bhcxrf"
      },
      "outputs": [],
      "source": [
        "import tenseal as ts\n",
        "import os\n",
        "\n",
        "def generate_ckks_context(save_path_public, save_path_secret):\n",
        "    \"\"\"\n",
        "    Generates and saves both public and secret CKKS contexts, including Galois keys.\n",
        "\n",
        "    Args:\n",
        "    - save_path_public (str): Path to save the public CKKS context (encryption only).\n",
        "    - save_path_secret (str): Path to save the secret CKKS context (decryption).\n",
        "\n",
        "    Returns:\n",
        "    - None\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Create directories if they don't exist\n",
        "        os.makedirs(os.path.dirname(save_path_public), exist_ok=True)\n",
        "        os.makedirs(os.path.dirname(save_path_secret), exist_ok=True)\n",
        "\n",
        "        # Create TenSEAL context for CKKS\n",
        "        context = ts.context(\n",
        "            ts.SCHEME_TYPE.CKKS,\n",
        "            poly_modulus_degree=8192,\n",
        "            coeff_mod_bit_sizes=[60, 40, 60]\n",
        "        )\n",
        "        context.global_scale = 2**21\n",
        "\n",
        "        # Generate Galois keys\n",
        "        context.generate_galois_keys()\n",
        "\n",
        "        # Verify private status before saving\n",
        "        if context.is_private():\n",
        "            print(\"The context is private before saving.\")\n",
        "        else:\n",
        "            raise Exception(\"The context is unexpectedly public after creation.\")\n",
        "\n",
        "        # Save the full context (with secret key) for decryption purposes\n",
        "        with open(save_path_secret, 'wb') as f:\n",
        "            f.write(context.serialize(save_secret_key=True))  # Explicitly save the secret key\n",
        "        print(f\"Secret CKKS context saved at: {save_path_secret}\")\n",
        "\n",
        "        # Remove the secret key and save the public context for encryption purposes\n",
        "        context.make_context_public()\n",
        "        with open(save_path_public, 'wb') as f:\n",
        "            f.write(context.serialize())\n",
        "        print(f\"Public CKKS context saved at: {save_path_public}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating CKKS contexts: {e}\")\n",
        "\n",
        "def verify_context_privacy(context_path):\n",
        "    \"\"\"\n",
        "    Verifies if a CKKS context loaded from a file is private or public.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(context_path, \"rb\") as f:\n",
        "            context = ts.context_from(f.read())\n",
        "\n",
        "        if context.is_private():\n",
        "            print(f\"The context loaded from {context_path} is private and can decrypt.\")\n",
        "        else:\n",
        "            print(f\"The context loaded from {context_path} is public and cannot decrypt.\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error verifying CKKS context: {e}\")\n",
        "\n",
        "####################################################################################################################################################################################################\n",
        "# Generate CKKS contexts\n",
        "save_path_public = \"/content/drive/MyDrive/CBIR_AES_FHE/data/save_path_public.pkl\"\n",
        "save_path_secret = \"/content/drive/MyDrive/CBIR_AES_FHE/data/save_path_secret.pkl\"\n",
        "generate_ckks_context(save_path_public, save_path_secret)\n",
        "\n",
        "# Verify the secret and public contexts after saving\n",
        "print(\"\\nVerifying saved contexts...\")\n",
        "verify_context_privacy(save_path_secret)  # Should be private\n",
        "verify_context_privacy(save_path_public)  # Should be public"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S-BdiXgQ5EC7"
      },
      "source": [
        "**Part 1: Creating Database, or Adding more images**. Process is as follows:\n",
        "\n",
        "1. The AES key is defined for encrypting the images.\n",
        "\n",
        "2. The system ensures a JSON file `mapping.json` exists to store the mapping between encrypted features and encrypted images.\n",
        "\n",
        "3.   User uploads all images they want to store securely in the system.\n",
        "\n",
        "4. The CKKS public context (used for encrypting feature vectors) is loaded (`save_path_public.pkl`).\n",
        "\n",
        "5. A ResNet-50 model is loaded and modified to remove its final classification layer, so it can be used for feature extraction.\n",
        "\n",
        "6. Each uploaded image is preprocessed (resized, normalized, and converted to tensor format) for compatibility with ResNet.\n",
        "\n",
        "7. The feature vector is extracted from the image using the ResNet model.\n",
        "\n",
        "8. The extracted feature vector is encrypted using CKKS homomorphic encryption and saved as in the specified folder `encrypted_features`.\n",
        "\n",
        "9. The original image is encrypted using AES and saved as in the specified folder `encrypted_images`, retaining the original file extension.\n",
        "\n",
        "10. The system updates a JSON file `mapping.json` , linking the encrypted feature file path to its corresponding encrypted image path.\n",
        "\n",
        "11. This process repeats for all uploaded images, completing secure storage.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xgyb07-zzJFZ"
      },
      "outputs": [],
      "source": [
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import pad\n",
        "from Crypto.Random import get_random_bytes\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import tenseal as ts\n",
        "import os\n",
        "import json\n",
        "\n",
        "# File paths\n",
        "ckks_public_context_path = \"/content/drive/MyDrive/CBIR_AES_FHE/data/save_path_public.pkl\"\n",
        "json_file_path = \"/content/drive/MyDrive/CBIR_AES_FHE/data/mapping.json\"\n",
        "encrypted_images_folder = \"/content/drive/MyDrive/CBIR_AES_FHE/data/encrypted_images\"\n",
        "encrypted_features_folder = \"/content/drive/MyDrive/CBIR_AES_FHE/data/encrypted_features\"\n",
        "\n",
        "# AES key (16 bytes for AES-128)\n",
        "aes_key = b'SixteenByteKey!!'\n",
        "\n",
        "# Ensure the mapping JSON file exists\n",
        "if not os.path.exists(json_file_path):\n",
        "    os.makedirs(os.path.dirname(json_file_path), exist_ok=True)\n",
        "    with open(json_file_path, \"w\") as json_file:\n",
        "        json.dump({}, json_file)\n",
        "\n",
        "# Load CKKS context\n",
        "def load_ckks_context(context_path):\n",
        "    try:\n",
        "        with open(context_path, 'rb') as f:\n",
        "            context = ts.context_from(f.read())\n",
        "        return context\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CKKS context: {e}\")\n",
        "        return None\n",
        "\n",
        "# Preprocess image for feature extraction\n",
        "def preprocess_image_for_feature_extraction(image_path):\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = preprocess(image)\n",
        "    return image.unsqueeze(0)\n",
        "\n",
        "# Extract features using ResNet\n",
        "def extract_features(model, preprocessed_image):\n",
        "    with torch.no_grad():\n",
        "        features = model(preprocessed_image)\n",
        "    return features.squeeze().numpy().flatten()\n",
        "\n",
        "# CKKS Encrypt feature vector\n",
        "def ckks_encrypt_feature_vector(feature_vector, public_context):\n",
        "    try:\n",
        "        return ts.ckks_vector(public_context, feature_vector.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"Error encrypting feature vector: {e}\")\n",
        "        return None\n",
        "\n",
        "# Updated AES Encrypt the image\n",
        "def aes_encrypt_image(image_path, key):\n",
        "    try:\n",
        "        # Read the image\n",
        "        with open(image_path, 'rb') as f:\n",
        "            image_data = f.read()\n",
        "\n",
        "        # Generate a random IV (Initialization Vector)\n",
        "        iv = get_random_bytes(AES.block_size)\n",
        "\n",
        "        # Create AES cipher object\n",
        "        cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "\n",
        "        # Pad the image data to ensure it's a multiple of block size\n",
        "        padded_data = pad(image_data, AES.block_size)\n",
        "\n",
        "        # Encrypt the image data\n",
        "        encrypted_data = cipher.encrypt(padded_data)\n",
        "\n",
        "        # Store the encrypted image data with the IV prepended\n",
        "        encrypted_image = iv + encrypted_data\n",
        "\n",
        "        return encrypted_image\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during AES encryption: {e}\")\n",
        "        return None\n",
        "\n",
        "####################################################################################################################################################################################################\n",
        "# Main encryption process\n",
        "public_context = load_ckks_context(ckks_public_context_path)\n",
        "if not public_context:\n",
        "    print(\"Failed to load CKKS public context.\")\n",
        "    exit()\n",
        "\n",
        "# Upload images\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove classification layer\n",
        "model.eval()\n",
        "\n",
        "for filename in uploaded.keys():\n",
        "    image_path = filename\n",
        "    preprocessed_image = preprocess_image_for_feature_extraction(image_path)\n",
        "\n",
        "    if preprocessed_image is not None:\n",
        "        # Extract and encrypt features\n",
        "        feature_vector = extract_features(model, preprocessed_image)\n",
        "        encrypted_vector = ckks_encrypt_feature_vector(feature_vector, public_context)\n",
        "\n",
        "        if encrypted_vector:\n",
        "            encrypted_feature_path = os.path.join(encrypted_features_folder, f\"encrypted_feature_{filename.split('.')[0]}.pkl\")\n",
        "            with open(encrypted_feature_path, 'wb') as f:\n",
        "                f.write(encrypted_vector.serialize())\n",
        "            print(f\"Encrypted feature vector saved at: {encrypted_feature_path}\")\n",
        "\n",
        "        # AES Encrypt the image\n",
        "        encrypted_image = aes_encrypt_image(image_path, aes_key)\n",
        "        if encrypted_image:\n",
        "            # Retain original file extension\n",
        "            file_name, file_extension = os.path.splitext(filename)\n",
        "            encrypted_image_path = os.path.join(encrypted_images_folder, f\"{file_name}_encrypted{file_extension}\")\n",
        "            with open(encrypted_image_path, 'wb') as f:\n",
        "                f.write(encrypted_image)\n",
        "            print(f\"Encrypted image saved at: {encrypted_image_path}\")\n",
        "\n",
        "            # Update JSON mapping\n",
        "            with open(json_file_path, \"r\") as json_file:\n",
        "                mapping_data = json.load(json_file)\n",
        "\n",
        "            mapping_data[encrypted_feature_path] = encrypted_image_path\n",
        "\n",
        "            with open(json_file_path, \"w\") as json_file:\n",
        "                json.dump(mapping_data, json_file, indent=4)\n",
        "\n",
        "            print(f\"Mapping updated: {encrypted_feature_path} -> {encrypted_image_path}\")\n",
        "        else:\n",
        "            print(f\"Skipping AES encryption for {filename} due to an error.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9QeXtCIZDcG"
      },
      "source": [
        "**Part 2: Retrieving Similar Images Based on a Query Image**.  Process is as follows:\n",
        "\n",
        "\n",
        "1. The CKKS private context (used for decrypting feature vectors) is loaded (`save_path_secret.pkl`).\n",
        "\n",
        "2. ResNet-50 model is loaded and modified by removing its final classification layer to use it for feature extraction.\n",
        "\n",
        "3. The user uploads the query image for which visually similar matches are to be found.\n",
        "\n",
        "4. The query image is preprocessed (resized, normalized, and converted to tensor format) for compatibility with ResNet.\n",
        "\n",
        "5. A feature vector is extracted from the query image using the ResNet model and is then encrypted using CKKS homomorphic encryption.\n",
        "\n",
        "6. The system loads all previously stored encrypted feature vectors from the `encrypted_features` folder.\n",
        "\n",
        "7. For each stored encrypted feature vector, both the query and stored vectors are compared using cosine similarity.\n",
        "\n",
        "8. If the similarity score exceeds 80%, the encrypted vector is considered a match.\n",
        "\n",
        "9. The system uses the JSON file `mapping.json` to locate the corresponding AES-encrypted image for each matching vector.\n",
        "\n",
        "10. The matched AES-encrypted images are decrypted using the AES key and displayed to the user.\n",
        "\n",
        "11. The decrypted images are also saved to the `decrypted_images` folder, from where the user can download them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Gy2Sn0zBOfSp"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "import tenseal as ts\n",
        "import os\n",
        "import json\n",
        "from Crypto.Cipher import AES\n",
        "from Crypto.Util.Padding import unpad\n",
        "import io\n",
        "\n",
        "# Paths\n",
        "ckks_secret_context_path = \"/content/drive/MyDrive/CBIR_AES_FHE/data/save_path_secret.pkl\"\n",
        "encrypted_features_folder = \"/content/drive/MyDrive/CBIR_AES_FHE/data/encrypted_features\"\n",
        "json_file_path = \"/content/drive/MyDrive/CBIR_AES_FHE/data/mapping.json\"\n",
        "decrypted_images_folder = \"/content/drive/MyDrive/CBIR_AES_FHE/data/decrypted_images\"\n",
        "\n",
        "# AES key (must match encryption key used earlier)\n",
        "aes_key = b'SixteenByteKey!!'\n",
        "\n",
        "# Create folder for decrypted images if it doesn't exist\n",
        "os.makedirs(decrypted_images_folder, exist_ok=True)\n",
        "\n",
        "# Load CKKS secret context\n",
        "def load_ckks_context(context_path):\n",
        "    try:\n",
        "        with open(context_path, 'rb') as f:\n",
        "            context = ts.context_from(f.read())\n",
        "        return context\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading CKKS context: {e}\")\n",
        "        return None\n",
        "\n",
        "# Preprocess image for ResNet input\n",
        "def preprocess_image_for_feature_extraction(image_path):\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ])\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = preprocess(image)\n",
        "    return image.unsqueeze(0)\n",
        "\n",
        "# Extract features using ResNet\n",
        "def extract_features(model, preprocessed_image):\n",
        "    with torch.no_grad():\n",
        "        features = model(preprocessed_image)\n",
        "    return features.squeeze().numpy().flatten()  # Ensure 1D vector\n",
        "\n",
        "# CKKS Encrypt feature vector\n",
        "def ckks_encrypt_feature_vector(feature_vector, secret_context):\n",
        "    try:\n",
        "        return ts.ckks_vector(secret_context, feature_vector.tolist())\n",
        "    except Exception as e:\n",
        "        print(f\"Error encrypting feature vector: {e}\")\n",
        "        return None\n",
        "\n",
        "# Compute cosine similarity between two decrypted vectors\n",
        "def compute_cosine_similarity(vector1, vector2):\n",
        "    dot_product = np.dot(vector1, vector2)\n",
        "    norm1 = np.linalg.norm(vector1)\n",
        "    norm2 = np.linalg.norm(vector2)\n",
        "    if norm1 == 0 or norm2 == 0:\n",
        "        return 0  # Handle zero magnitude vector case\n",
        "    return dot_product / (norm1 * norm2)\n",
        "\n",
        "from IPython.display import display\n",
        "\n",
        "def aes_decrypt_image(encrypted_image_path, key, output_folder):\n",
        "    try:\n",
        "        # Read the encrypted image\n",
        "        with open(encrypted_image_path, 'rb') as f:\n",
        "            encrypted_data = f.read()\n",
        "\n",
        "        # Extract the IV from the first 16 bytes\n",
        "        iv = encrypted_data[:16]\n",
        "        encrypted_data = encrypted_data[16:]  # Rest is the actual encrypted data\n",
        "\n",
        "        # Create AES cipher object with the same key and IV\n",
        "        cipher = AES.new(key, AES.MODE_CBC, iv)\n",
        "\n",
        "        # Decrypt the data\n",
        "        decrypted_data = unpad(cipher.decrypt(encrypted_data), AES.block_size)\n",
        "\n",
        "        # Save to a BytesIO object to emulate a file\n",
        "        image_stream = io.BytesIO(decrypted_data)\n",
        "\n",
        "        # Attempt to open as an image\n",
        "        img = Image.open(image_stream)\n",
        "\n",
        "        # Display the image inline in Colab\n",
        "        display(img)  # Display the decrypted image in Colab\n",
        "\n",
        "        # Save the decrypted image\n",
        "        decrypted_image_path = os.path.join(output_folder, f\"decrypted_{os.path.basename(encrypted_image_path)}.png\")\n",
        "        img.save(decrypted_image_path)\n",
        "        return decrypted_image_path\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error during decryption: {e}\")\n",
        "        return None\n",
        "\n",
        "\n",
        "# Compare encrypted feature vectors and decrypt similar ones\n",
        "def compare_and_decrypt(query_vector, secret_context):\n",
        "    similar_vectors = []\n",
        "    if not os.path.exists(json_file_path):\n",
        "        print(f\"Mapping file not found at {json_file_path}\")\n",
        "        return similar_vectors\n",
        "\n",
        "    # Load mapping\n",
        "    with open(json_file_path, \"r\") as json_file:\n",
        "        mapping_data = json.load(json_file)\n",
        "\n",
        "    for file_name in os.listdir(encrypted_features_folder):\n",
        "        if file_name.endswith(\".pkl\"):\n",
        "            encrypted_vector_path = os.path.join(encrypted_features_folder, file_name)\n",
        "            with open(encrypted_vector_path, \"rb\") as f:\n",
        "                encrypted_vector = ts.ckks_vector_from(secret_context, f.read())\n",
        "\n",
        "            # Decrypt both vectors\n",
        "            decrypted_query_vector = query_vector.decrypt()\n",
        "            decrypted_stored_vector = encrypted_vector.decrypt()\n",
        "\n",
        "            # Compute similarity\n",
        "            similarity = compute_cosine_similarity(decrypted_query_vector, decrypted_stored_vector) * 100\n",
        "            if similarity > 80:\n",
        "                similar_vectors.append((file_name, similarity))\n",
        "                aes_encrypted_image_path = mapping_data.get(encrypted_vector_path)\n",
        "                if aes_encrypted_image_path:\n",
        "                    print(f\"Decrypting AES image for {file_name}...\")\n",
        "                    decrypted_image_path = aes_decrypt_image(aes_encrypted_image_path, aes_key, decrypted_images_folder)\n",
        "                    if decrypted_image_path:\n",
        "                        print(f\"Decrypted image saved at: {decrypted_image_path}\")\n",
        "    return similar_vectors\n",
        "\n",
        "####################################################################################################################################################################################################\n",
        "# Main process\n",
        "def main():\n",
        "    # Load CKKS secret context\n",
        "    secret_context = load_ckks_context(ckks_secret_context_path)\n",
        "    if not secret_context:\n",
        "        print(\"Failed to load CKKS secret context.\")\n",
        "        return\n",
        "\n",
        "    # Load ResNet model\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model = torch.nn.Sequential(*list(model.children())[:-1])  # Remove the classification layer\n",
        "    model.eval()\n",
        "\n",
        "    # Upload image\n",
        "    from google.colab import files\n",
        "    uploaded = files.upload()\n",
        "\n",
        "    for filename in uploaded.keys():\n",
        "        image_path = filename\n",
        "\n",
        "        # Preprocess and extract features\n",
        "        try:\n",
        "            preprocessed_image = preprocess_image_for_feature_extraction(image_path)\n",
        "            feature_vector = extract_features(model, preprocessed_image)\n",
        "        except Exception as e:\n",
        "            print(f\"Error processing {image_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # Encrypt the feature vector\n",
        "        query_encrypted_vector = ckks_encrypt_feature_vector(feature_vector, secret_context)\n",
        "        if query_encrypted_vector is None:\n",
        "            print(f\"Failed to encrypt feature vector for {image_path}.\")\n",
        "            continue\n",
        "\n",
        "        # Compare with existing vectors and decrypt similar ones\n",
        "        try:\n",
        "            similar_vectors = compare_and_decrypt(query_encrypted_vector, secret_context)\n",
        "            if similar_vectors:\n",
        "                print(f\"Similar vectors for {image_path}:\")\n",
        "                for vector_name, similarity in similar_vectors:\n",
        "                    print(f\"  {vector_name}: {similarity:.2f}%\")\n",
        "            else:\n",
        "                print(f\"No similar vectors found for {image_path}.\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error finding similar vectors for {image_path}: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxpqedDeppOQ"
      },
      "source": [
        "This function is to delete the folders. *(for reset, not required for normal working)*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6iA6XZJbnAb5"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Path to the folder\n",
        "folder_path = \"/content/drive/MyDrive/CBIR_AES_FHE/scripts\"\n",
        "\n",
        "# Delete all contents of the folder\n",
        "shutil.rmtree(folder_path)  # Deletes the folder and all its contents\n",
        "os.makedirs(folder_path, exist_ok=True)  # Recreates the folder if needed\n",
        "print(f\"All contents of the folder '{folder_path}' have been deleted.\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}